seed: 2222
clean: 6
debug: False
train: True
result: evaluate  # evaluate, instance_numbers, sagittalcenters
load_directory: # /home/phalendj/code/rsna2024/outputs/2024-08-29/14-29-59  # For reloads
mode: valid

directories:
  relative_directory: /data/phalendj/kaggle/rsna2024
  image_directory: train_images


dataset:
  name: FullLevelDataset
  image_size: [512, 512]
  # conditions: [Spinal Canal Stenosis, Left Neural Foraminal Narrowing, Right Neural Foraminal Narrowing, Left Subarticular Stenosis, Right Subarticular Stenosis]
  # conditions: [Left Neural Foraminal Narrowing, Right Neural Foraminal Narrowing]  # Use Clean level 6
  # conditions: [Left Subarticular Stenosis, Right Subarticular Stenosis]  # Need clean level 6
  conditions: [Spinal Canal Stenosis]  # Need clean level 6
  sagittal_channels: 23  # 99th percentile distance for foraminal is 48mm, with this spacing we will get 66 mm span around center instance which should cover it.
  sagittal_subsize: 112
  sagittal_span_mm: 50
  sagittal_slice_dx: 3
  axial_channels: 11  # median distance for vertebrae is 26-32mm depending on vertebrae, with this spacing we will get 15 mm span around center instance
  axial_subsize: 224
  axial_span_mm: 60
  axial_slice_dx: 3
  aug_size: 0.2
  # center_file: /home/phalendj/code/rsna2024/outputs/2024-08-16/15-40-19/all_predicted_center_coordinates.csv
  # center_file: /data/phalendj/kaggle/rsna2024/train_labels_sagittal_t1.csv
  center_file: /data/phalendj/kaggle/rsna2024/train_label_coordinates.csv
  augmentations:
    prob: 0.75
    normalize: True  # Helpful with generalization
    hflip: False   # Very hurtful usually - cannot segment properly and everything comes in standard locations
    contrast: True  # Not much change
    blur: True   # This is a major adjustment that helps with training.
    distort: True  # This is a major adjustment that helps with training.  This one does the most to keep training and val in line, however it may prevent training from getting too good, especially for axial
    rotate: True  # This is a major adjustment that helps with training.
    crop:   # 0.9 Does not do much - Maybe crop more? 0.7 hurts
      use: False
      size: 512
    channel_shuffle: False  # Removes all the information for TDCNN
    sharpen: False
  
  

loss:
  name: WeightedCrossEntropy
  # name: InstanceCrossEntropy
  # name: SevereLoss
  # name: HeatmapLoss
  # patch_size: 512
  
model:
  name: FullLevelTDCNN
  # model_name: tf_efficientnetv2_b2.in1k
  # nclasses: 15
  model_name: densenet121
  nclasses: 3  # 6 with L/R, 3 for spinal
  num_layers: 4
  use: all
  preload: # /home/phalendj/code/rsna2024/outputs/2024-08-26/12-08-32/

optimization:
  optimizer: AdamW
  learning_rate: 1.0e-4
  weight_decay: 1.e-2

  # scheduler: CosineWithWarmup
  # n_cycles: 0.475

  scheduler: MultiStepLR
  milestones: [5, 10]
  gamma: 0.1

training:
  use_folds: [0, 1, 2, 3, 4]
  # use_folds: [2]
  use_amp: True
  epochs: 15
  batch_size: 6
  grad_acc: 1
  early_stopping: 5
  workers: 12

